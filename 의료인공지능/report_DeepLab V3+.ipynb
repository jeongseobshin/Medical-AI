{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"report_DeepLab V3+.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"mount_file_id":"1jhZ7ik1Qbgk_OEAy8I0mT-WCermh4j59","authorship_tag":"ABX9TyMjmpAaGG3kgvPVd6SiVcHf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"52xgmrEbuwI7"},"source":["from __future__ import print_function\n","\n","import os\n","import numpy as np\n","\n","import cv2\n","\n","\n","\n","\n","image_rows = 256\n","image_cols = 256\n","skip = 1\n","\n","def read_imgs(img_path, mask_path):\n","\n","    images = os.listdir(img_path) # 파일이름 저장 리스트\n","    total = len(images)  # 파일갯수\n","\n","    mask_images = os.listdir(mask_path)  # 마스크\n","    mask_total = len(mask_images)\n","\n","    imgs = np.zeros((total//skip, image_rows, image_cols), dtype=np.uint8)\n","    mask_imgs = np.zeros((mask_total//skip, image_rows, image_cols), dtype=np.uint8)\n","\n","    if(total != mask_total):\n","        print ('Error in number of images and mask_images')\n","        return imgs,mask_imgs\n","\n","    i = 0\n","    print('Making numpy array from images...')\n","    for image_name in images:\n","        if i % skip == 0 and i//skip < total//skip :\n","            print (i, i//skip)\n","            img = cv2.imread(os.path.join(img_path, image_name), cv2.IMREAD_GRAYSCALE)\n","            tmp = cv2.resize(img, (image_cols, image_rows), interpolation=cv2.INTER_CUBIC)\n","            imgs[i//skip] = tmp\n","\n","            img = cv2.imread(os.path.join(mask_path, image_name), cv2.IMREAD_GRAYSCALE)\n","            tmp = cv2.resize(img, (image_cols, image_rows), interpolation=cv2.INTER_CUBIC)\n","            mask_imgs[i//skip] = tmp\n","        i += 1\n","    print(str(total//skip) + '  Loading done.')\n","\n","    return imgs, mask_imgs\n","\n","from google.colab.patches import cv2_imshow\n","\n","def vis_img_mask(imgs, mask_imgs, wn):\n","\n","    size = int(imgs.shape[0]/5)\n","    w = imgs.shape[2]\n","    h = imgs.shape[1]\n","    t_img = np.zeros((2*h,6*w), np.uint8)\n","    \n","    for i in range (5):\n","        t_img[0:h,i*w:i*w+w] = imgs[i*size]\n","        t_img[h:h+h,i*w:i*w+w] = mask_imgs[i*size]\n","    t_img[0:h,5*w:5*w+w] = imgs[imgs.shape[0]-1]\n","    t_img[h:h+h,5*w:5*w+w] = mask_imgs[imgs.shape[0]-1]\n","\n","    cv2_imshow(t_img)\n","\n","\n","data_dir = 'drive/MyDrive/python/data/raw-cmr-small/'\n","\n","def create_train_data():\n","\n","    imgs, mask_imgs = read_imgs(data_dir+'train', data_dir+'train_mask')\n","    np.save('imgs_train.npy', imgs)\n","    np.save('imgs_mask_train.npy', mask_imgs)\n","\n","    vis_img_mask(imgs, mask_imgs, 'train')\n","\n","\n","def load_train_data():\n","    imgs_train = np.load('imgs_train.npy')\n","    imgs_mask_train = np.load('imgs_mask_train.npy')\n","    return imgs_train, imgs_mask_train\n","\n","\n","def create_test_data():\n","\n","    imgs, mask_imgs = read_imgs(data_dir+'test', data_dir+'test_mask')\n","    np.save('imgs_test.npy', imgs)\n","    np.save('imgs_mask_test.npy', mask_imgs)\n","\n","    vis_img_mask(imgs, mask_imgs, 'test')\n","\n","\n","def load_test_data():\n","    imgs_test = np.load('imgs_test.npy')\n","    imgs_mask_test = np.load('imgs_mask_test.npy')\n","    return imgs_test, imgs_mask_test\n","\n","if __name__ == '__main__':\n","    create_train_data()\n","    create_test_data()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YsqZYTgt4EhF"},"source":["\"\"\"[ 구글 colab 에서의 unet train.py 예제 프로그램 ]\n","\n","\n","---\n","\n","\n","\"\"\"\n","\n","# npy 영상을 읽어 (img_rows, img_cols) 크기로 영상을 resize 하고 위 keras data 형식으로 \n","# 누적하여 만들어줌.  \n","# 영상을 255로 나누어 level을 정규화 하고 u-net 에 입력하여 train 하고 test 함.\n","\n","from __future__ import print_function\n","import cv2\n","import numpy as np\n","from keras.models import Model\n","from keras.layers import Input, concatenate, Dropout, Conv2D, Conv3D\n","from keras.layers import MaxPooling2D, MaxPooling3D, Conv2DTranspose, UpSampling2D\n","from keras.layers import BatchNormalization, Activation\n","from keras.layers import Reshape, Dense, multiply, Add, Concatenate\n","from keras.optimizers import Adam\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n","from keras import backend as K\n","from keras import models\n","from keras import callbacks\n","\n","img_rows = 256  # u-net 입력영상 높이\n","img_cols = 256   # u-net 입력영상 너비\n","ch = 3 ##수정## 4->3\n","\n","smooth = 1.\n","\n","#data_path = 'drive/My Drive/raw-cmr-small/'\n","data_path = './'\n","\n","import tensorflow as tf\n","config = tf.compat.v1.ConfigProto()\n","config.gpu_options.allow_growth = True\n","session = tf.compat.v1.Session(config=config)\n","\n","def load_train_data():\n","    imgs_train = np.load(data_path+'imgs_train.npy')\n","    imgs_mask_train = np.load(data_path+'imgs_mask_train.npy')\n","    return imgs_train, imgs_mask_train\n","\n","def load_test_data():\n","    imgs_test = np.load(data_path+'imgs_test.npy')\n","    imgs_mask_test = np.load(data_path+'imgs_mask_test.npy')\n","    return imgs_test, imgs_mask_test\n","\n","# 테스트 결과를 dice_coef로 평가, 완전히 겹치면 1로 100%, 0 이면 0%\n","# 테스트 결과는 테스트 영상으로 확인\n","# y_true : 테스트 영상의 나와야 할 결과 \n","# y_pred : 테스트 영상을 입력했을 때 u-net 결과\n","\n","\n","\n","def dice_coef(y_true, y_pred):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n","\n","def dice_coef_loss(y_true, y_pred):\n","    return -dice_coef(y_true, y_pred)\n","\n","\n","# def preprocess(imgs):\n","\n","#     # 4D keras 데이타 형식의 numpy 배열 만들기, imgs.shape[0]가 영상 개수\n","#     # imgs 는 data.py에서 만들어 저장한 파일\n","#     imgs_p = np.ndarray((imgs.shape[0], img_rows, img_cols, ch), dtype=np.uint8)\n","\n","#     for i in range(imgs.shape[0]):\n","#         tmp1 = cv2.resize(imgs[i], (img_cols, img_rows), \n","#                     interpolation=cv2.INTER_CUBIC)\n","#         # tmp1은 (img_rows, img_cols) 크기의 2D 영상. \n","#         # 이 tmp1을 (imgs.shape[0], img_rows, img_cols, 1) 4D 배열에 넣기\n","#         imgs_p[i,:,:,0] = tmp1  # ch이 1 이상인 경우 의미에 맞게 추가\n","#     return imgs_p\n","\n","def preprocess(imgs):\n","    imgs_p = np.ndarray((imgs.shape[0], img_rows, img_cols, ch), dtype=np.uint8)\n","    for i in range(imgs.shape[0]):\n","        tmp1 = cv2.resize(imgs[i], (img_cols, img_rows), interpolation=cv2.INTER_CUBIC)\n","        imgs_p[i,:,:,0] = tmp1\n","        imgs_p[i,:,:,1] = tmp1\n","        imgs_p[i,:,:,2] = tmp1\n","\n","    return imgs_p\n","\n","# def preprocess_mask(imgs):\n","#     imgs_p = np.ndarray((imgs.shape[0], img_rows, img_cols, 1), dtype=np.uint8)\n","#     for i in range(imgs.shape[0]):\n","#         tmp = cv2.resize(imgs[i], (img_cols, img_rows), \n","#                          interpolation=cv2.INTER_CUBIC)\n","#         imgs_p[i,:,:,0] = tmp\n","#         #imgs_p[i,:,:,1] = 255-tmp\n","#     return imgs_p\n","\n","def preprocess_mask(imgs):\n","    imgs_p = np.ndarray((imgs.shape[0], img_rows, img_cols, 2), dtype=np.uint8)\n","    for i in range(imgs.shape[0]):\n","        tmp = cv2.resize(imgs[i], (img_cols, img_rows), interpolation=cv2.INTER_CUBIC)\n","        imgs_p[i,:,:,0] = tmp\n","        imgs_p[i,:,:,1] = 255-tmp\n","    return imgs_p\n","\n","\n","def train_and_predict():\n","    print('Loading and preprocessing train data...')\n","    imgs_train, imgs_mask_train = load_train_data()\n","\n","    imgs_train = preprocess(imgs_train)\n","    imgs_mask_train = preprocess_mask(imgs_mask_train)\n","\n","    t_img = imgs_train[0, :, :, 0]\n","    \n","    from google.colab.patches import cv2_imshow\n","    cv2_imshow(t_img)\n","    #cv2.imshow(\"img\", t_img)\n","    #cv2.moveWindow(\"img\", 20, 20);\n","    #cv2.waitKey(100)\n","\n","    t_img = imgs_mask_train[0, :, :, 0]\n","    cv2_imshow(t_img)\n","    #cv2.imshow(\"mask\", t_img)\n","    #cv2.moveWindow(\"mask\", 20, 320);\n","    #cv2.waitKey(100)\n","\n","    # 영상 level 0~1로 정규화\n","    imgs_train = imgs_train.astype('float32') / 255\n","    imgs_mask_train = imgs_mask_train.astype('float32') / 255\n","\n","##수정##\n","    # validation data set : hyperparameter\n","    # np.random.seed(1234)\n","    # valid_size = int(0.2*imgs_train.shape[0])\n","    # random_index = np.random.choice(imgs_train.shape[0], imgs_train.shape[0], \n","    #                  replace=False) # 100개인 경우 100개를 random하게 섞는다.\n","    # valid_imgs_train = imgs_train[random_index[:valid_size]] # 0~20까지\n","    # valid_imgs_mask_train = imgs_mask_train[random_index[:valid_size]]\n","    # imgs_train = imgs_train[random_index[valid_size:]]  # 20~100까지\n","    # imgs_mask_train = imgs_mask_train[random_index[valid_size:]]\n","\n","    print('Creating and compiling model...')\n","\n","    # model = get_unet2()\n","    # model.summary()\n","\n","    # model_checkpoint=ModelCheckpoint('Deeplabv3.hdf5',monitor='loss',save_best_only=True) ##수정##\n","\n","    from model import Deeplabv3\n","\n","    model = Deeplabv3(weights=None,input_tensor=None,input_shape=(img_rows, img_cols, ch),\n","                      classes=2, backbone='xception',OS=16,alpha=1.,activation='softmax')\n","    \n","    model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy']) \n","    model.summary()\n","    \n","\n","    # batch_size는 GPU에서 일괄 처리 단위. GPU 메모리에 맞게 최대한 크게 설정하는 것이\n","    # 속도가 빠름. 특별한 이유없이 CPU memory alloc error가 나면 컴퓨터 재부팅 후 시도\n","    \n","    print('Fitting model...')\n","    epoch = 10\n","    history = model.fit(imgs_train, imgs_mask_train, batch_size=2, epochs=epoch,\n","                        verbose=1, shuffle=True)\n","                        # validation_data=(valid_imgs_train, valid_imgs_mask_train), \n","                        # callbacks=[model_checkpoint]) ##수정##\n","\n","    history_dict = history.history\n","    print(history_dict)\n","    loss_values = history_dict['loss']\n","    # val_loss_values = history_dict['val_loss'] ##수정##\n","    print(loss_values)\n","    # print(val_loss_values)\n","\n","    epochs = range(1, epoch + 1)\n","\n","    from matplotlib import pyplot as plt\n","    plt.plot(epochs, loss_values, 'b+', label='Training loss')\n","    # plt.plot(epochs, val_loss_values, 'g+', label='Validation loss') ##수정##\n","    plt.title('Training')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","\n","    plt.show()\n","\n","\n","    # test 영상에 대해 segmentation 하기\n","    print('Loading and preprocessing test data...')\n","    imgs_test, imags_mask_test = load_test_data()\n","    imgs_test = preprocess(imgs_test)\n","    imags_mask_test = preprocess(imags_mask_test)\n","\n","    imgs_test = imgs_test.astype('float32') / 255\n","    imags_mask_test = imags_mask_test.astype('float32') / 255\n","\n","    print('Loading saved weights...')\n","    # 이부분 decode() 오류 나면 다음 설치 : pip install h5py==2.9.0\n","    !pip install h5py==2.9.0\n","    model.load_weights('unet.hdf5')\n","\n","    print('Predicting masks on test data...')\n","    imgs_test_pred = model.predict(imgs_test, batch_size=2, verbose=1)\n","    np.save('imgs_test_pred.npy', imgs_test_pred) ##수정## data_path 삭제\n","\n","    # dice coef로 성능 구하기\n","##수정##\n","    # smooth = 1.\n","    # dice_coeff = 0.0\n","    # for i in range(imgs_test.shape[0]):\n","    #     y_true_f = imags_mask_test[i,:,:,0]\n","    #     y_pred_f = imgs_test_pred[i,:,:,0]\n","\n","    smooth = 1.\n","    dice_coeff = 0.0\n","    for i in range(imgs_test.shape[0]):\n","        y_true_f = cv2.threshold(imags_mask_test[i,:,:,0], 0.5,1., cv2.THRESH_BINARY)[1].astype(np.uint8)\n","        y_pred_f = cv2.threshold(imgs_test_pred[i,:,:,0], 0.5, 1., cv2.THRESH_BINARY)[1].astype(np.uint8)\n","\n","        intersection = np.sum(y_true_f * y_pred_f)\n","        dice = (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)\n","        dice_coeff = dice_coeff + dice\n","        print (i, dice)\n","    dice_coeff = dice_coeff / imgs_test.shape[0]\n","    print (dice_coeff)\n","\n","    # groud_truth(mask)와 결과값(imgs_test_pred) sample display\n","    # 전체 중 5개 만 display\n","    size = imags_mask_test.shape[0]//5\n","    w = imags_mask_test.shape[2]\n","    h = imags_mask_test.shape[1]\n","    t_img = np.zeros((2*h,5*w), np.uint8)\n","    for i in range (5):\n","        t_img[0:h,i*w:i*w+w] = 255*imags_mask_test[i*size][:,:,0]\n","        t_img[h:h+h,i*w:i*w+w] = 255*imgs_test_pred[i*size][:,:,0]\n","\n","    cv2.putText(t_img, 'ground-truth', (0,20), 2, 1, (192, 192, 192))\n","    cv2.putText(t_img, 'result', (0,256+20), 2, 1, (192, 192, 192))\n","    cv2_imshow(t_img)\n","    #cv2.imshow('mask', t_img)\n","    #cv2.moveWindow('mask', 20,0);\n","    #cv2.waitKey(0)\n","\n","if __name__ == '__main__':\n","    train_and_predict()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eHuttf6J4FX4"},"source":["\"\"\"[ 구글 colab 에서의 unet color_view.py 예제 프로그램 ]\n","\n","\"\"\"\n","\n","from __future__ import print_function\n","\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","img_cols = 256\n","img_rows = 256\n","\n","#data_path = 'drive/My Drive/raw-cmr-small/‘\n","data_path = './'\n","\n","def prep(img):\n","    img = img.astype('float32')\n","    img = cv2.threshold(img, 0.7, 1., cv2.THRESH_BINARY)[1]\n","    img = cv2.resize(img, (img_cols, img_rows))\n","    return img\n","\n","def set_view():\n","    imgs_test = np.load(data_path+'imgs_test.npy')\n","    imgs_test_pred = np.load(data_path+'imgs_test_pred.npy')\n","    total=imgs_test.shape[0]\n","\n","    print (imgs_test_pred.shape)\n","\n","    dt_img = np.ndarray((total, img_rows, img_cols), dtype=np.uint8)\n","    rgb_img = np.ndarray((total, img_rows, img_cols, 3), dtype=np.uint8)\n","\n","    for m in range(total):\n","\n","        print (m)\n","\n","        gray_img = imgs_test[m]\n","        gray_img = cv2.resize(gray_img, (img_cols, img_rows))\n","\n","        t_img = imgs_test_pred[m,:,:,0]\n","        t_img = cv2.resize(t_img, (img_cols, img_rows))\n","        dt_img[m] = 255*t_img\n","\n","        bin_img = prep(t_img)\n","\n","        kernel = np.ones((3,3), np.uint8)\n","        dilated_img = cv2.dilate(128*bin_img, kernel, iterations=1)\n","\n","        boundary_img = dilated_img * (1-bin_img)\n","\n","        rgb_img[m][:,:,0] = gray_img\n","        rgb_img[m][:,:,1] = np.clip(gray_img + boundary_img, 0, 255)\n","        rgb_img[m][:,:,2] = gray_img\n","\n","    return rgb_img, dt_img\n","\n","\n","view_imgs, dt_imgs = set_view()\n","\n","imgs_test_pred = np.load(data_path+'imgs_test_pred.npy')\n","d_cnt = imgs_test_pred.shape[0]\n","\n","fig, ax = plt.subplots(d_cnt, 2, figsize=(20,60))\n","\n","for m in range(imgs_test_pred.shape[0]):\n","    plt.subplot(d_cnt, 2, 2*m+1)   # 행의갯수, 열의갯수, 위치\n","    plt.imshow(dt_imgs[m], cmap=\"gray\", vmax=255)\n","    plt.subplot(d_cnt, 2, 2*m+2)   # 행의갯수, 열의갯수, 위치\n","    plt.imshow(view_imgs[m])\n","\n","plt.show()"],"execution_count":null,"outputs":[]}]}
